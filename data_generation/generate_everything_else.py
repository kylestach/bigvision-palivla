import tensorflow as tf
import numpy as np
import argparse
import json
import torch
import os

from helpers.molmo_coords import remove_null, get_obj_coords
from helpers.sam import get_masks
from helpers.detr import DETRModel

from octo.data.oxe import make_oxe_dataset_kwargs
from octo.data.dataset import make_single_dataset

from PIL import Image
import io

TRAJS_TO_PROCESS = 5200
WRITE_INTERVAL=25

parser = argparse.ArgumentParser()
parser.add_argument("--id", type=int)
parser.add_argument("--dataset", type=str)
parser.add_argument("--size", type=int, default=16)
args = parser.parse_args()

assert args.id < args.size

OBJECT_NAMES_PATH = f"/global/scratch/users/riadoshi/vla/generated_data/{args.dataset}/jsons/object_names/batch{args.id}.json"
FINAL_JSON = f"/global/scratch/users/riadoshi/vla/generated_data/{args.dataset}/jsons/all/batch{args.id}.json"
MASKS_PATH = f"/global/scratch/users/riadoshi/vla/generated_data/{args.dataset}/masks/batch{args.id}"

if not os.path.exists(MASKS_PATH):
    os.mkdir(MASKS_PATH)

dtype = torch.bfloat16
print("Loading DETR *******", flush=True)
detr_model = DETRModel(model_name='detr-finetuned-fractal-bridge-dw')

tf.config.set_visible_devices(
    [], device_type="gpu"
)
tf.config.set_visible_devices(
    [], device_type="GPU"
)

# load chunk of dataset in based on ID
print("Loading dataset *******")
start_idx = TRAJS_TO_PROCESS*args.id
dataset_kwargs = make_oxe_dataset_kwargs(args.dataset,"/global/scratch/users/riadoshi/data/")
dataset = make_single_dataset(
                                dataset_kwargs, 
                                frame_transform_kwargs=dict(
                                    resize_size={"primary": (256, 256)},
                                ),
                                train=True)
dataset = dataset.skip(start_idx).take(TRAJS_TO_PROCESS)
iterator = dataset.iterator()

# load object names dict
with open(OBJECT_NAMES_PATH, "r") as file:
    object_names_dict = json.load(file)

# if final json path already exists, load it in
results_dict = {}
if os.path.exists(FINAL_JSON):
    print("loading existing JSON!", flush=True)
    with open(FINAL_JSON, "r") as file:
        results_dict = json.load(file)

# uncomment if you want to make sure it reloaded the existing json
assert results_dict is not None

for i, episode in enumerate(iterator):
    # write dictionary if it's time
    if (i+1)%WRITE_INTERVAL==0:
        with open(FINAL_JSON, "w") as f:
            json.dump(results_dict, f)

    traj_id = int(episode['traj_idx'][0])
    print(f"Processing traj {traj_id} **********", flush=True)

    # skip traj if we've already processed it
    if str(traj_id) in results_dict:
        print("skipping traj ", traj_id, flush=True)
        continue
   
    images = episode['observation']['image_primary'].squeeze()
    language_label = episode['task']['language_instruction'][0].decode()

    # this process will OOM if the trajectory length is >100. check for this, and skip if it's too long
    if len(images)>160:
        results_dict[traj_id] = {}
        continue

    # query detr for gripper centroids
    gripper_centroids = detr_model.eval(
            images_np=images, 
            batch_size=16, 
            threshold=0.1
     )
     
    ### GET COORDINATES OF OBJECTS ### 

    # get the object names for this trajectory 
    object_names = object_names_dict[f"{traj_id}"]

    # skip trajs with no identified objects
    if len(object_names)==0:
        results_dict[traj_id] = {}
        continue

    # get first-frame object coordinates from molmo
    object_coords = get_obj_coords(
        img=images[0],
        objs=object_names
    )

    # filter out any null coordinates and object names before feeding to sam
    object_names, object_coords = remove_null(
        obj_names=object_names, 
        obj_coords=object_coords
    )

    # if molmo couldn't identify the coordinates of any object, skip this traj
    if len(object_names)==0:
        results_dict[traj_id] = {}
        continue

    # create a dictionary mapping object names to ids
    obj_id_to_name = {}
    for obj_id, obj_name in enumerate(object_names):
        obj_id_to_name[f'obj{obj_id}'] = obj_name


    ### GET OBJ MASKS & CENTROIDS PER STEP ### 

    # get seg masks from SAM2
    seg_masks = get_masks(
        object_coords=object_coords,
        images=images
    )

    ## SAVE EVERYTHING DOWN ###

    # create results dict for this trajectory
    results_dict[traj_id] = {}
    results_dict[traj_id]['language_label'] = language_label

    # save down obj id to obj name mapping
    results_dict[traj_id]['obj_id_to_name'] = obj_id_to_name

    # save down object names & coords generated by MOLMO
    results_dict[traj_id]['object_coords'] = {}
    for object_name, (x,y) in zip(object_names, object_coords):
        results_dict[traj_id]['object_coords'][object_name] = f"{x},{y}"
    
    # save down gripper centroids generated by DETR
    # we flip these points to be consistent with PaliGemma format (see notion for explanation)
    results_dict[traj_id]['gripper_centroids'] = {}
    for step, coord in enumerate(gripper_centroids):
        if coord is None:
            results_dict[traj_id]['gripper_centroids'][step] = None
        else:
            x,y = coord
            results_dict[traj_id]['gripper_centroids'][step] = f"{y},{x}" # flipping point to be consistent with PaliGemma format


    # save down segmentation masks generated by SAM2
    obj_ids = obj_id_to_name.keys()
    obj_id_to_masks = {obj_id: [] for obj_id in obj_ids}
    obj_id_to_mask_centroids = {obj_id: [] for obj_id in obj_ids}

    for step, masks in seg_masks.items():
        for obj_id, (_, mask) in zip(obj_ids, masks.items()): # mask is a numpy array
            
            # squeeze extra dim out of mask (1,256,256) ->  (256, 256)
            mask = mask.squeeze()
            
            # get the centroid of the seg mask
            segmented_indices = np.argwhere(mask.squeeze())
            if len(segmented_indices)==0: # append none if the object was not detected in this frame
                obj_centroid = (None, None)
            else:
                obj_centroid = np.mean(segmented_indices, axis=0).round(2) # round to 2 decimal places
            obj_id_to_mask_centroids[obj_id].append(obj_centroid)

            # create bytes object
            mask_byte_arr = io.BytesIO()

            # save np array of mask to the bytes object
            mask_img = Image.fromarray(mask.astype(np.uint8))
            mask_img.save(mask_byte_arr, format='JPEG', quality=95)
            
            # append the mask bytes object to the object trajectory
            obj_id_to_masks[obj_id].append(mask_byte_arr.getvalue())

            # release memory
            mask_byte_arr.flush()
            mask_byte_arr.seek(0)

    # save centroids
    results_dict[traj_id]['obj_id_to_centroids'] = {}
    for obj_id, centroids in obj_id_to_mask_centroids.items():
        results_dict[traj_id]['obj_id_to_centroids'][obj_id] = {}
        for step, centroid in enumerate(centroids):
            results_dict[traj_id]['obj_id_to_centroids'][obj_id][step] = f"{centroid[0]},{centroid[1]}" 

    # write seg masks immediately, before we OOM
    seg_path = f"{MASKS_PATH}/{traj_id}"
    if not os.path.exists(seg_path):
        os.mkdir(seg_path)
    for obj_id, mask_byte_arr in obj_id_to_masks.items():
        mask_bytes_np = np.array(mask_byte_arr, dtype=object)
        np.savez(f'{seg_path}/{obj_id}.npz', mask_bytes=mask_bytes_np)

    results_dict[traj_id]['mask_path'] = seg_path
    


with open(FINAL_JSON, "w") as f:
    json.dump(results_dict, f)
    
print(f"FINISHED BATCH {args.id} FOR DATASET {args.dataset}!", flush=True)
    

